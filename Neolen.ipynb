{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec6a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.0.187-py3-none-any.whl (960 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m960.7/960.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: openai in ./anaconda3/lib/python3.10/site-packages (0.27.5)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Using cached tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<2,>=1\n",
      "  Downloading pydantic-1.10.8-cp310-cp310-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./anaconda3/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in ./anaconda3/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in ./anaconda3/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./anaconda3/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: requests<3,>=2 in ./anaconda3/lib/python3.10/site-packages (from langchain) (2.28.1)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./anaconda3/lib/python3.10/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./anaconda3/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./anaconda3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./anaconda3/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./anaconda3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: packaging>=17.0 in ./anaconda3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (22.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./anaconda3/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Installing collected packages: typing-inspect, tenacity, pydantic, marshmallow, openapi-schema-pydantic, marshmallow-enum, dataclasses-json, langchain\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "Successfully installed dataclasses-json-0.5.7 langchain-0.0.187 marshmallow-3.19.0 marshmallow-enum-1.5.1 openapi-schema-pydantic-1.2.4 pydantic-1.10.8 tenacity-8.2.2 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99e206d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in ./anaconda3/lib/python3.10/site-packages (from python-docx) (4.9.1)\n",
      "Building wheels for collected packages: python-docx\n",
      "  Building wheel for python-docx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184490 sha256=71930fb3f306af90ff801b6d51b7afdabcda503a760c1ced1a3b1e0bc9d18d3f\n",
      "  Stored in directory: /Users/ahmadbader/Library/Caches/pip/wheels/65/e1/9b/0c38fe6cfe02a9fe31cb6b4efd90985f17354d7f77872f2def\n",
      "Successfully built python-docx\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-0.8.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef227151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc7e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import docx\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Set up OpenAI API credentials\n",
    "openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "def generate_default_answer(question):\n",
    "    # List of common default answers\n",
    "    default_answers = [\n",
    "        \"I'm sorry, but I don't have an answer for that.\",\n",
    "        \"I'm afraid I couldn't find the information you're looking for.\",\n",
    "        \"Apologies, I don't have the answer to that question.\",\n",
    "        \"Unfortunately, I couldn't find any relevant information to answer your question.\",\n",
    "        \"Regrettably, I don't have the necessary information to provide an answer.\",\n",
    "    ]\n",
    "    \n",
    "    # Choose a random default answer from the list\n",
    "    default_answer = random.choice(default_answers)\n",
    "    \n",
    "    return default_answer\n",
    "\n",
    "\n",
    "# Function to extract text from Word documents\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    text = ' '.join([paragraph.text for paragraph in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "# Function to extract text from PDF files\n",
    "def extract_text_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PdfReader(file)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to process uploaded files and generate an answer\n",
    "def generate_answer(files, question):\n",
    "    content = \"\"\n",
    "    for file_path in files:\n",
    "        if file_path.endswith(\".docx\"):\n",
    "            extracted_text = extract_text_from_docx(file_path)\n",
    "        elif file_path.endswith(\".pdf\"):\n",
    "            extracted_text = extract_text_from_pdf(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file_path}\")\n",
    "            continue\n",
    "        \n",
    "        content += extracted_text + \"\\n\"\n",
    "\n",
    "    # Prepare input for the model\n",
    "    prompt = f\"Question: {question}\\nFiles Content: {content}\\nAnswer:\"\n",
    "    \n",
    "    # Generate answer using GPT-3.5 model\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=100,\n",
    "        temperature=0.7,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        timeout=30\n",
    "    )\n",
    "    \n",
    "    # Extract the generated answer from the response\n",
    "    answer = response.choices[0].text.strip()\n",
    "    \n",
    "    # If the answer is empty, generate a default answer\n",
    "    if not answer:\n",
    "        answer = generate_default_answer(question)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "question = input(\"Ask a question: \")\n",
    "file_paths = input(\"Enter the paths of the files (separated by commas): \").split(\",\")\n",
    "\n",
    "answer = generate_answer(file_paths, question)\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362003e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
